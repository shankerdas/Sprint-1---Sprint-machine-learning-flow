{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint 1 -  Sprint machine learning flow.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOK03D11ODxmzF+yAjrj8b5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SLK0JOtm-QWR"},"source":["# The purpose of this Sprint"]},{"cell_type":"markdown","metadata":{"id":"IBzZ2XTC-U9A"},"source":["* Know the practical flow of machine learning\n","* Complete a model with high generalization performance"]},{"cell_type":"markdown","metadata":{"id":"WfUKxSje5ZtK"},"source":["#[Problem 1] Cross Validation"]},{"cell_type":"code","metadata":{"id":"ZXVQ2cWv50KL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616418773104,"user_tz":0,"elapsed":5673,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}},"outputId":"1b64ab43-4708-4ebd-9582-7935c27d4ce0"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import KFold\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score\n","\n","# loading the csv of the dataset\n","df = pd.read_csv('application_train.csv')\n","df = df.select_dtypes('number')\n","\n","# cleaning the dataset by filling the empy data(null)\n","cleaned_df = df.fillna(0)\n","\n","# get only existing data with no missing values\n","cleaned_df = cleaned_df[cleaned_df.columns[~cleaned_df.isnull().all()]]\n","\n","# separating them into variables\n","y = cleaned_df['TARGET']\n","X = cleaned_df.drop(['TARGET'], axis=1)\n","\n","X = X.to_numpy()\n","\n","kf = KFold(n_splits=2)\n","\n","for train_index, test_index in kf.split(X):\n","    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TRAIN: [153756 153757 153758 ... 307508 307509 307510] TEST: [     0      1      2 ... 153753 153754 153755]\n","TRAIN: [     0      1      2 ... 153753 153754 153755] TEST: [153756 153757 153758 ... 307508 307509 307510]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DoaNoarq6GbB"},"source":["Standardizing the data"]},{"cell_type":"code","metadata":{"id":"iEjiHFrt6JiR","executionInfo":{"status":"ok","timestamp":1616418780525,"user_tz":0,"elapsed":1016,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}}},"source":["scaler = StandardScaler()\n","scaler.fit(X_train)\n","X_train_trans = scaler.transform(X_train)\n","X_test_trans = scaler.transform(X_test)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hubBR1jH6O_5"},"source":["#[Problem 2] Grid search"]},{"cell_type":"code","metadata":{"id":"P0bv1m_X6UFe"},"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","\n","# checking which model and params are best\n","model_params = {\n","    'random_forest':{\n","        'model': RandomForestClassifier(),\n","        'params': {\n","            'n_estimators': [1,5,10]\n","        }\n","    },\n","    'logic_regression':{\n","        'model': LogisticRegression(solver=\"liblinear\",multi_class=\"auto\"),\n","        'params': {\n","            'C': [1,5,10]\n","        }\n","    }\n","}\n","\n","# defining an array to store the scores\n","scores = []\n","\n","for model_name,mp in model_params.items():\n","    clf = GridSearchCV(mp['model'],mp['params'], return_train_score=False)\n","    clf.fit(X_train_trans,y_train)\n","    scores.append({\n","        'model': model_name,\n","        'best_score': clf.best_score_,\n","        'best_params': clf.best_params_\n","    })\n","\n","best_model_params = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n","best_model_params"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GBu5PmNh6aHV"},"source":["#[Problem 3] Survey from Kaggle Notebooks"]},{"cell_type":"markdown","metadata":{"id":"Omdmo6Fl6deD"},"source":["* Hyperparameter Tuning using Grid search\n","* Gradient Boosting Machine\n","* Using one type of data\n","* Early stopping"]},{"cell_type":"markdown","metadata":{"id":"Z6bKUYgs6rKL"},"source":["#[Problem 4] Creating a model with high generalization performance"]},{"cell_type":"code","metadata":{"id":"gvmyxb-i6vam"},"source":["import lightgbm as lgb\n","\n","# creating an instance of the model\n","model = lgb.LGBMClassifier()\n","\n","# save the default params\n","default_params = model.get_params()\n","\n","# number of folds\n","N_FOLDS = 5\n","\n","# creating a dataset\n","train_set = lgb.Dataset(data = X_train)\n","\n","# Cross validation results when avoid overfitting\n","cv_results = lgb.cv(default_params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, metrics = 'auc', nfold = N_FOLDS, seed = 42)\n","\n","# displaying the results\n","print('The maximum validation ROC AUC was: {:.5f}.'.format(cv_results['auc-mean'][-1]))\n","print('The optimal number of boosting rounds (estimators) was {}.'.format(len(cv_results['auc-mean'])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FLyttI526-E-"},"source":["* I have imported the whole dataset\n","* I created a subset of only numbers\n","* I split the data using kfold\n","* I used gridsearchCV to find the best model and params to fine tune my classiffiers\n","* After finding the results i tested the LGBM classifier and checked it ROC which is good\n","\n","**All of the techniques learnt are used through out the whole task in every problem**"]},{"cell_type":"markdown","metadata":{"id":"-lZ0Mxiz7IWl"},"source":["#[Problem 5] Final model selection"]},{"cell_type":"code","metadata":{"id":"_GXAICfo7e66"},"source":["# loading the csv of the test dataset\n","test_df = pd.read_csv('application_test.csv')\n","\n","# cleaning the dataset by removing the empy data(null)\n","test_cleaned_df = test_df.fillna(0)\n","\n","# separating them into variables\n","test_X = test_cleaned_df.select_dtypes('number')\n","\n","# standardizing the data\n","test_scaler = StandardScaler()\n","test_X_test_trans = scaler.fit_transform(test_X)\n","\n","# predicting\n","test_reg_pred = clf.predict(test_X_test_trans)\n","\n","kgl_submission = pd.concat([test_df['SK_ID_CURR'], pd.Series(test_reg_pred, name='TARGET')], axis=1)\n","kgl_submission.to_csv(' ', index=False)"],"execution_count":null,"outputs":[]}]}